\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{palotti15}
\citation{palotti15}
\citation{palotti15}
\citation{palotti15}
\newlabel{chp:appendix}{{}{1}{Appendix}{section*.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Understandability label distribution for CLEF eHealth 2016\relax }}{1}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dist}{{1}{1}{Understandability label distribution for CLEF eHealth 2016\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Understandability distribution broken per topic for CLEF eHealth 2016\relax }}{1}{figure.caption.3}}
\newlabel{fig:dist}{{2}{1}{Understandability distribution broken per topic for CLEF eHealth 2016\relax }{figure.caption.3}{}}
\bibcite{palotti15}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces In Palotti et al.\nobreakspace  {}\cite  {palotti15}, authors investigates the influence of HTML preprocessing when readability formulas are used to estimate Webpage understandability. They found that readability formulas are heavily affected by the methods used to extract text from the HTML source, but they did not measure how correlated each method was with a human ground truth. We further extended Palotti et al.'s work to understand the influence of HTML preprocessing on automatic understandability methods and establish best practices. We show the correlation of each preprocessing combination with the ground truth assessments for \textbf  {CLEF 2015}.\relax }}{2}{figure.caption.4}}
\newlabel{fig:dist}{{3}{2}{In Palotti et al.~\cite {palotti15}, authors investigates the influence of HTML preprocessing when readability formulas are used to estimate Webpage understandability. They found that readability formulas are heavily affected by the methods used to extract text from the HTML source, but they did not measure how correlated each method was with a human ground truth. We further extended Palotti et al.'s work to understand the influence of HTML preprocessing on automatic understandability methods and establish best practices. We show the correlation of each preprocessing combination with the ground truth assessments for \textbf {CLEF 2015}.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces In Palotti et al.\nobreakspace  {}\cite  {palotti15}, authors investigates the influence of HTML preprocessing when readability formulas are used to estimate Webpage understandability. They found that readability formulas are heavily affected by the methods used to extract text from the HTML source, but they did not measure how correlated each method was with a human ground truth. We further extended Palotti et al.'s work to understand the influence of HTML preprocessing on automatic understandability methods and establish best practices. We show the correlation of each preprocessing combination with the ground truth assessments for \textbf  {CLEF 2016}.\relax }}{3}{figure.caption.5}}
\newlabel{fig:dist}{{4}{3}{In Palotti et al.~\cite {palotti15}, authors investigates the influence of HTML preprocessing when readability formulas are used to estimate Webpage understandability. They found that readability formulas are heavily affected by the methods used to extract text from the HTML source, but they did not measure how correlated each method was with a human ground truth. We further extended Palotti et al.'s work to understand the influence of HTML preprocessing on automatic understandability methods and establish best practices. We show the correlation of each preprocessing combination with the ground truth assessments for \textbf {CLEF 2016}.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Correlations between understandability estimators and human assessments for \textbf  {CLEF 2015}.\relax }}{4}{figure.caption.6}}
\newlabel{fig:dist}{{5}{4}{Correlations between understandability estimators and human assessments for \textbf {CLEF 2015}.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Correlations between understandability estimators and human assessments for \textbf  {CLEF 2015}.\relax }}{5}{figure.caption.7}}
\newlabel{fig:dist}{{6}{5}{Correlations between understandability estimators and human assessments for \textbf {CLEF 2015}.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces To study the impact of feature sets, we varied the number of features each regressor algorithm was trained with. For that, we selected features with Python's f\_regression algorithm from Sklearn package. The eXtreme Gradient Boosting (XGB) and Random Forest Regressor were marginally influenced by the selection of features, therefore we used XGB with all features devised in our experiments.\relax }}{6}{figure.caption.8}}
\newlabel{fig:dist}{{7}{6}{To study the impact of feature sets, we varied the number of features each regressor algorithm was trained with. For that, we selected features with Python's f\_regression algorithm from Sklearn package. The eXtreme Gradient Boosting (XGB) and Random Forest Regressor were marginally influenced by the selection of features, therefore we used XGB with all features devised in our experiments.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces We expanded retrieval results including the experiments with Reciprocal Rank Fusion (RRF) of Dale-Chall Index Runs (indices 4-12) and the original runs (indices 1-3). These results confirm the superiority of using XGB rather than DCI in terms of understandability of the results retrieved.\relax }}{6}{figure.caption.9}}
\newlabel{fig:dist}{{8}{6}{We expanded retrieval results including the experiments with Reciprocal Rank Fusion (RRF) of Dale-Chall Index Runs (indices 4-12) and the original runs (indices 1-3). These results confirm the superiority of using XGB rather than DCI in terms of understandability of the results retrieved.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Results obtained by integrating understandability estimations within retrieval methods on \textbf  {CLEF 2015}. Baseline runs are reported at table indices 1-3 (the index column is labelled Index). Re-ranking experiments are reported at indices 4-21. Fusion experiments are reported at indices 22-30. Learning to rank experiments are reported at indices 31-35. All measures were calculated up to rank n = 10. The highest result of each set of experiments is reported in bold face.\relax }}{7}{figure.caption.10}}
\newlabel{fig:dist}{{9}{7}{Results obtained by integrating understandability estimations within retrieval methods on \textbf {CLEF 2015}. Baseline runs are reported at table indices 1-3 (the index column is labelled Index). Re-ranking experiments are reported at indices 4-21. Fusion experiments are reported at indices 22-30. Learning to rank experiments are reported at indices 31-35. All measures were calculated up to rank n = 10. The highest result of each set of experiments is reported in bold face.\relax }{figure.caption.10}{}}
