\section{Related Work}
\label{sec:related}
Understandability refers to the ease of comprehension of the information that is presented to a user; put in other words, health information is understandable ``when consumers of diverse backgrounds and varying levels of health literacy can process and explain key messages''~\cite{shoemaker2014development}. Often the terms understandability and readability are used interchangeably: in this paper we use readability to refer to formulas and methods that estimate how easy is to understand a text, usually based on its words and sentences. We use understandability to refer to the more general concept of ease of understanding: this is affected by text readability\footnote{Increasing readability tends to improve understanding~\cite{ley1996use}.}, but may also be influenced by how legible is a text and its layout, including e.g., the use of images to explain difficult concepts.

There is a large body of literature that has examined the understandability of Web health content when the information seeker is a member of the general public. \todo{For example ...}
A common finding of these studies is that, in general, health content available on Web pages is often hard to understand by the general public; this includes content that is retrieved in top ranked positions by current commercial search engines.

Previous Linguistics and Information Retrieval research has attempted to devise computational methods for the automatic estimation of text readability and understandability, and for the inclusion of these within search methods or their evaluation. Computational approaches to understandability estimations include (1) readability formulas, which exploit word surface characteristics of the text, (2) machine learning approaches, (3) matching with specialised dictionaries or terminologies, often compiled with information about understandability difficulty.

Measures such as Coleman-Liau Index (CLI)~\cite{cli75}, Dale-Chall Index (DCI)~\cite{dale48}, Flesch Reading Easy (FRE)~\cite{flesch75}, Simple Measure of Gobbledygook (SMOG)~\cite{smog69} belong to the first category. These measures generally rely on surface-level characteristics of text, such as characters, syllables and word counts~\cite{dubay04}.
While these metrics have been widely used in studies investigating the understandability of health content retrieved by search engines (e.g.,~\cite{becker2004study,graber99readability,fitzsimmons2010readability,wiener2013readability,patel13readability,atcherson14readability,meillier17readability}), Palotti et al. found that these measures are heavily affected by the methods used to extract text from the HTML source~\cite{palotti15}. They were able to identify specific settings of an HTML preprocessing pipeline that provided consistent  estimates. We shall revisit this work in more details in Section~\ref{sec:pipelines}, as we further investigate this problem by comparing the effect of HTML preprocessing on text understandability estimations in light of explicit human assessments. 

The use of Machine Learning to estimate document understandability is the second category. Earlier research explored as machine learning features the use of statistical natural language and language modeling (\cite{liu04,collins05,heilman07}) as well as linguistic factors~\cite{pitler08}, such as the syntactic features or lexical cohesion. While we replicate here many of the features devised in these works, they focus on estimating readability of general English documents rather than medical ones. In the medical domain, Zeng et al. explored features such as word frequency in different medical corpora to estimate concept familiarity, which originated the Consumer Health Vocabulary (CHV) terminology~\cite{zeng05,zeng06,zeng08}.  

The actual use of the Consumer Health Vocabulary or of other terminologies such as the Medical Subject Headings (MeSH) belongs to the third category. The CHV is a prominent medical vocabulary dedicated to mapping consumer (layperson) vocabulary to technical terms~\cite{zeng06}. It attributes a score for each of its concepts with respect to their difficulty, with lower/higher scores for harder/easier concepts. Researcher have been using CHV to tasks such as document analysis~\cite{leroy08} and medical expertise prediction~\cite{palotti14}.
The hierarchy of MeSH was previously used in the literature to identify hard concepts, assuming that a concept that is deep in the hierarchy is harder than a shallow one~\cite{yan11}. Other approaches combined vocabularies with word surface characteristics and syntactic features like part of speech into a unique readability measure~\cite{kim2007beyond}.

In this work, we investigate approaches to estimate understandability from each of these categories. We further extend Palotti et al.'s work to understand the influence of HTML preprocessing on automatic understandability methods and establish best practices. 

Some prior work has attempted to use understandability estimations for improving search results in consumer health search; as well as methods to evaluate retrieval systems that do account for understandability along with topical relevance. Palotti et al.~\cite{palotti2016ranking} have used learning to rank with standard retrieval features along with features based on readability measures and medical lexical aspects to determine
understandability. Van Doorn et al.~\cite{van2016balancing} have shown that learning a set of rankers that provide trade-offs across a number of relevance criteria, including readability/understandability, increase overall system effectiveness.   
Zuccon and Koopman~\cite{zuccon14}, and later Zuccon~\cite{zuccon2016understandability} have proposed and investigated a family of measures based on the gain-discount framework, where the gain of a document is influenced by both its topical relevance and its understandability. They showed that, although generally correlated, topical-relevance evaluation alone provides differing system rankings compared to understandability-biased evaluation measures. 
In this work we further explore the development of retrieval methods that combine signals about topical relevance and understandability. 


