\section{Related Work}
\label{sec:related}
Understandability refers to the ease of comprehension of the information that is presented to a user; put in other words, health information is understandable ``when consumers of diverse backgrounds and varying levels of health literacy can process and explain key messages''~\cite{shoemaker2014development}. Often the terms understandability and readability are used interchangeably: in this paper we use readability to refer to formulas and methods that estimate how easy is to understand a text, usually based on its words and sentences. In turn, we use understandability to refer to the more general concept of ease of understanding: this is affected by text readability\footnote{Increasing readability tends to improve understanding~\cite{ley1996use}.}, but may also be influenced by how legible are its contents and layout, including e.g., the use of images to explain difficult concepts.

There is a large body of literature that has examined the understandability of Web health content when the information seeker is a member of the general public. \todo{For example ...}
A common finding of these studies is that, in general, health content available on Web pages is often hard to understand by the general public; this includes content that is retrieved in top rank positions by current commercial search engines.

Previous Linguistics and Information Retrieval research has attempted to devise computational methods for the automatic estimation of text readability and understandability, and for the inclusion of these within search methods or their evaluation. Computational approaches to understandability estimations include (1) readability formulas, which exploit word surface characteristics of the text, (2) matching with specialised dictionaries or terminologies, often compiled with information about understandability difficulty, (3) machine learning approaches.

Measures such as Coleman-Liau Index (CLI)~\cite{cli75}, Dale-Chall Index (DCI)~\cite{dale48}, Flesch Reading Easy (FRE)~\cite{flesch75}, Simple Measure of Gobbledygook (SMOG)~\cite{smog69} belong to the first category. These measures generally rely on surface-level characteristics of text, such as characters, syllables and word counts~\cite{dubay04}.
While these metrics have been widely used in studies investigating the understandability of health content retrieved by search engines (e.g.,~\cite{becker2004study,graber99readability,fitzsimmons2010readability,wiener2013readability,patel13readability,atcherson14readability,meillier17readability}), Palotti et al. found that these measures are heavily affected by the methods used to extract text from the HTML source~\cite{palotti15}. They were able to identify specific settings of an HTML preprocessing pipeline that provided consistent  estimates. We shall revisit this work in more details in Section~\ref{sec:pipelines}, as we further investigate this problem by comparing the effect of HTML preprocessing on text understandability estimations in light of explicit human assessments. 


The use of the Consumer Health Vocabulary (CHV) or of terminologies like the Medical Subject Headings (MeSH) belongs to the second category. The Consumer Health Vocabulary (CHV) is a prominent medical vocabulary dedicated to mapping consumer (layperson) vocabulary to technical terms~\cite{zeng06}. It attributes a score for each of its concepts with respect to their difficulty, with lower/higher scores for harder/easier concepts.
The hierarchy of Medical Subject Headers (MeSH) was previously used in the literature to identify hard concepts, assuming that a concept that is deep in the hierarchy is harder than a shallow one~\cite{yan11}. Other approaches combined vocabularies with word surface characteristics and syntactic features like part of speech into a unique readability measure~\cite{kim2007beyond}.


Use of Machine Learning for understandability: \todo{anything in health specifically? JP: See comments on slack + \cite{wu13,wu16}}

In this work, we investigate approaches to estimate understandability from each of these categories. We further extend Palotti et al.'s work to understand the influence of HTML preprocessing on automatic understandability methods and establish best practices with this regard. 

Some prior work has attempted to use understandability estimations for improving search results in consumer health search; as well as methods to evaluate retrieval systems that do account for understandability along with topical relevance. Palotti et al.~\cite{palotti2016ranking} have used learning to rank with standard retrieval features along with features based on readability measures and medical lexical aspects to determine
understandability. van Doorn et al.~\cite{van2016balancing} have shown that learning a set of rankers that provide trade-offs across a number of relevance criteria, including readability/understandability, increase overall system effectiveness.   
Zuccon and Koopman~\cite{zuccon14}, and later Zuccon~\cite{zuccon2016understandability} have proposed and investigated a family of measures based on the gain-discount framework, where the gain of a document is influenced by both its topical relevance and its understandability. They showed that, although generally correlated, topical-relevance evaluation alone provides differing system rankings compared to understandability-biased evaluation measures. 
In this work we further explore the development of retrieval methods that combine signals about topical relevance and understandability. 


