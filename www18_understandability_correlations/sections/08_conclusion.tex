
\section{Conclusion}
\label{sec:conclusion_doc_analysis}

In this paper we have examined approaches to estimate the understandability of health Web pages, including the impact of HTML preprocessing techniques, and how to integrate these within retrieval methods to provide more understandable search results for people seeking health information. 

The empirical experiments suggested that: (1) machine learning methods based on regression are best suited to estimate the understandability of health Web pages; (2) preprocessing does affect effectiveness (both for understandability prediction and document retrieval), although, compared to other methods, machine learning-based methods for understandability estimation are less subject to variability due to poor preprocessing; (3) learning to rank methods can be specifically trained to promote more understandable search results. 

This paper makes a clear contribution to improving search engines tailored to consumer health search because it thoroughly investigates promises and pitfalls of understandability estimations and their integration into retrieval methods. The paper further highlights which methods and settings do provide better search results to health information seekers. As shown in Figure~\ref{fig:dist}, these methods would clearly improve current health-focused search engines. 


%\mytodo{Needs to be re-written}
%
%There is an abundance of factors that affect how readability is perceived by users. 
%In this paper we devised and studied a large number of readability estimators, ranging from traditional readability formulas extensively used in the past 50 years to state-of-the-art machine learning algorithms.
%We grouped them into semantically related groups in order to visualize their correlation with human assessments collected during CLEF eHealth campaigns in 2015 and 2016.
%
%Complementary to the literature research~\cite{palotti15}, we evaluated how preprocessing steps impact the readability estimation in traditional readability formulas and in other modern estimators. We empirically learnt the importance of preprocessing steps when applying readability formulas, as the highest correlations happen when other than the Naive method is used.
%For the most modern estimators, such as the ones based on machine learning methods, the correlation is less sensitive to the preprocessing steps.
%
%We also studied the correlation of each individual readability formula with the human assessment to provide insights into which formula should be preferred. Our analysis concluded that the Simple Measure of Gobbledygook (SMOG) and Dale-Chall Index (DCI) were the most correlated metrics for the two datasets studied and, together with Coleman-Liau Index (CLI) and the Flesch Reading Ease (FRE) are the most stable metrics across datasets, and therefore, should be preferred.


