
\input{tables/tab_kendall}


\section{Rank Correlations} %across Systems and Measures}
\label{sec:clef}

In addition to the synthetic experiments studied in Section~\ref{sec:simulations}, we aim to understand how the proposed $H$ framework correlates with metrics from the UBIRE framework.
For that, we use the participating systems in CLEF eHealth campaigns of 2015 and 2016~\cite{clefIR15,clefIR16}, in which systems were officially evaluated on their $uRBP$ score.
Our goal is to understand the correlation among the regular RBP, $uRBP$, and our proposed $RBP_u$ and $H_{RBP}$.

It is necessary to define $RBP_u(\rho)$ for both CLEF eHealth 2015 and 2016 in order to evaluate systems using the H framework. 
Understandability in 2015 was collected with 4 labels (very easy, easy, hard and very hard)~\cite{clefIR15}: we assume that a document labelled as very easy and easy are relevant documents in the understandability dimension, while the others are non-relevant.
In 2016, understandability labels were collected as integers ranging from 0 (very easy) to 100 (very hard)~\cite{clefIR16}. Based on the distribution of understandability scores, we make the assumption that documents with a label lower than 40 are relevant for the understandability dimension, while the others are non-relevant.

Table~\ref{tab:kendall} shows the Kendall-$\tau$ rank correlation of system in both CLEF 2015 and 2016 according to RBP, $uRBP$, $RBP_u$ and $H_{RBP}$. 
In both in 2015 and 2016, the correlation between RBP and $uRBP$ is very high (0.90 and 0.94). This emphasizes once more that RBP and $uRBP$ are tightly bounded.
In turn, the metric that strongest correlates with $RBP_u$ is $H_{RBP}$, and it only weakly correlates with RBP and $uRBP$.
Finally, $H_{RBP}$ correlation with RBP is high (0.84 in 2015 and 0.85 in 2016), but not as strong as the correlation between RBP and $uRBP$.
The correlation between $H_{RBP}$ and $uRBP$ shows that $H_{RBP}$ is as capable as $uRBP$ to rank systems.

\mytodo{Something else?}
 
