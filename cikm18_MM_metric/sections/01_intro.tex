\section{Introduction}
%\section{Evaluation Metrics of Understandability in Search Engines}
\label{chp:evaluation_metrics}

Research has long established that the notion of relevance in information retrieval (IR) is multidimensional~\cite{schamber94,borlund03}: the topicality of a document to a query or information need is central to the notion of relevance, but other factors (also called dimensions) that influence the relevance of a document do exist. These include novelty and diversity, timeliness, scope, understandability and trustworthiness, among others~\cite{park93,schamber94}. In the context of consumer health search\footnote{This search task involves common people with no or limited medical knowledge searching for health advice on the web. This task is often carried out in time-sensitive and emotion-pressured circumstances~\cite{hersh08,mishra2014time}.}, in particular, the relevance dimensions of understandability and information trustworthiness are fundamental~\cite{hersh08}. 
It means that health information is only valuable to users, allowing them to make appropriate health decision if it is understandable and correct. 
It is therefore important to take into account these relevance dimensions, along with topicality, when evaluating the effectiveness of search systems in the context of consumer health search tasks, and in general in other tasks with similar requirements.

An evaluation framework that integrates understandability into IR evaluation has been recently devised~\cite{zuccon14,zuccon16} and it has been largely adopted to evaluate systems for consumer health search~\cite{clefIR15,clefIR16,clefIR17}. The framework, named \textit{understandability-biased IR evaluation} (UBIRE), builds upon the gain-discount framework of evaluation measures used in IR (measures like normalised Discounted Cumulative Gain (nDCG),
Expected Reciprocal Rank (ERR) and Rank Biased Precision metric (RBP) belong to this framework)~\cite{carterette11}. UBIRE uses a discount based on the rank position at which documents are retrieved, and a gain function that integrates contributions from both topicality and understandability (see Section~\ref{sec:understandability_metrics}). The framework has been extended to integrate additional relevance dimensions such as trustworthiness~\cite{clefIR17}: since its extension is straightforward, without loss of generality, we refer to the UBIRE framework as the extended version capable of including in the gain function every dimension of relevance (provided certain assumptions are met). 

A limitation of the approach used to model multidimensional relevance in UBIRE is that it is not trivial to identify how different dimensions of relevance affect the final evaluation score. This is because in UBIRE gains produced by documents for each of the considered dimensions of relevance are combined early on in the evaluation measure. This limitation makes the interpretation of evaluation results using UBIRE difficult as it is impossible to determine whether improvements (deteriorations) are due to more (less) understandable or more (less) topical documents being retrieved. 

In this work, we propose an alternative to UBIRE, called the $MM$ framework, that overcomes the interpretability limitation of UBIRE, while still enabling the combination of multidimensional relevance evidence when evaluating IR systems (Section~\ref{sec:extension}). Using small synthetic data we show the intuitive differences between UBIRE and $MM$ and demonstrate how $MM$ overcomes UBIRE's limitation (Section~\ref{sec:simulations}). We further empirically compare specific measures instantiated from the two frameworks using real data to study systems ranking correlations across UBIRE and $MM$ (Section~\ref{sec:clef}). The results show that while system correlations measured with $MM$ are aligned with UBIRE, $MM$ provides richer information to researchers, allowing them to assess and control how each relevance dimension contributes
to the evaluation score of a system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


