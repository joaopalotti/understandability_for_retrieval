\section{Incorporating Understandability into Evaluation Metrics}
\label{sec:understandability_metrics}
The understandability-biased IR evaluation framework (UBIRE)~\cite{zuccon14,zuccon16} is based on the gain-discount framework~\cite{carterette11} which models an evaluation measure $\mathcal{M}$ as:
%
\vspace{-4pt}
\begin{equation*}
\mathcal{M} = \frac{1}{\mathcal{N}} \sum_{k=1}^{K} \mathtt{d}(k) \mathtt{g}(d@k)
\end{equation*}
%
%where $\mathtt{g}(d@k)$ and $\mathtt{d}(k)$ are respectively the \textit{gain function} computed for the (relevance of the) document at rank $k$ (i.e. $d@k$) and the \textit{discount function} computed for the rank $k$.
%$K$ is the depth of assessment at which measure $\mathcal{M}$ is evaluated, and $1/\mathcal{N}$ is an optional normalization factor, which serves to bound the value of the sum into the range [0,1] (details in~\cite{carterette11}).
where $\mathtt{g}(d@k)$ and $\mathtt{d}(k)$ are respectively the \textit{gain function} computed for the document at rank $k$ and the \textit{discount function} computed for the rank $k$.
$K$ is the depth of assessment at which measure $\mathcal{M}$ is evaluated, and $1/\mathcal{N}$ is a normalization factor, which serves to bound the value of the sum into the range [0,1] (details in~\cite{carterette11}).

The gain-discount framework encompasses measures such as the normalized Discounted Cumulative Gain (nDCG)~\cite{jarvelin02} with $\mathtt{g}(d@k) = 2^{P(R|d@k)} - 1$ and $\mathtt{d}(k) = 1/(log_2(1 + k))$; the expected reciprocal rank (ERR)~\cite{chapelle09} with $\mathtt{g}(d@K) =  (2^{P (R|d@k)} - 1)/2^{max(P (R|d))}$ and $\mathtt{d}(k) = 1/k$; and the Rank Biased Precision (RBP) with $\mathtt{g}(d@k)$ equal to 1 if $d@k$ is relevant and 0 otherwise and $\mathtt{d}(k) = \rho^{k-1}$ (with $\rho$ representing the user persistence).

The gain provided by a document at rank $k$ can be expressed as a function of its probability of relevance. Without loss of generality, $\mathtt{g}(d@k) = f(P(R|d@k))$, where $P(R|d@k)$ is the probability of relevance given the document at $k$. 
When only topical relevance is modelled, then $P(R|d@k) = P(T|d@k)$, i.e., the probability that the document at $k$ is topically relevant. 
For binary relevance, this probability is 1 for relevant documents and 0 for non-relevant documents. For non-binary relevance, this probability can be distributed according to the number of relevance levels.

UBIRE extends this framework to consider cases where relevance is modelled beyond topicality so as to explicitly model other dimensions, such as understandability.
This is done by modelling the probability of relevance $P(R|d@k)$ as the joint distribution over all considered dimensions, $P(\delta_1, \cdots, \delta_n|d@k)$, where each $\delta_i \in \mathcal{D}$ represents a dimension of relevance, e.g., topicality, understandability. The computation is simplified by assuming that dimensions are compositional events and their probabilities independent (see~\cite{zuccon16} for more details). The gain function with respect to different dimensions of relevance can then be expressed as:

\vspace{-12pt}
\begin{eqnarray*}
    \mathtt{g}(d@k) &=& f(P(R|d@k)) \\
    &=& f\big(P(\delta_1, \cdots, \delta_n|d@k)\big) = f\Big(\prod_{i=1}^n P(\delta_i|d@k)\Big) 
\end{eqnarray*}


Evaluation metrics developed within this framework differ by means of the instantiations of $f\big(P(\delta_1, \cdots, \delta_n|d@k)\big)$, other than by which dimensions are modelled. Zuccon provided an instantiation that considers both topicality and understandability~\cite{zuccon16}:
%
\vspace{-4pt}
\begin{equation*}
\mathtt{g}(d@k) = f(P(R|d@k)) = f\big(P(T|d@k) \cdot P(U|d@k)\big)
\end{equation*}

Specific implementations of the UBIRE framework that have been developed in previous work considered the basic gain and discount functions from RBP~\cite{moffat08}; an instantiation with understandability~\cite{zuccon14,zuccon16} has been later extended by jointly considering also trustworthiness~\cite{clefIR17}. For ease of explanation, we consider the formulation with topicality and understandability; similar considerations apply when also trustworthiness is modelled (as well as other dimensions). In this case, the understandability-biased RBP, $uRBP$, is defined as: 
%
\vspace{-4pt}
\begin{eqnarray*}
    uRBP(\rho) &=& (1-\rho) \sum_{k=1}^{K} \rho^{k-1} P(T|d@k) \cdot P(U|d@k)\\ 
&=& (1-\rho) \sum_{k=1}^{K} \rho^{k-1} \mathtt{g}_{RBP}(d@k) \cdot \mathtt{g}_{U}(d@k)
\label{eq:RBP}
\end{eqnarray*}
\vspace{-6pt}

In the $uRBP$, the function $\mathtt{g}_{RBP}(d@k)$ is the same as the gain in RBP and transforms relevance values into the corresponding gains and, likewise, $\mathtt{g}_{U}(d@k)$ transforms understandability values into the corresponding gains. 
If $\mathtt{g}_{U}(d@k)=1$ for every document, then only topical relevance affects retrieval evaluation, i.e. every document is considered as having equal understandability and we obtain the original RBP. Two instantiations of the gain function $\mathtt{g}_{U}(d@k)$ have been explored in previous work: one binary (\textit{uRBP}) and the other graded (\textit{uRBPgr}). In the binary version $\mathtt{g}_{U}(d@k) = 1$ if $P(U|d@k) \geq th_U$, where $th_U$ is a threshold on the assessments of understandability (every assessment that is greater than or equal to $th_U$ would generate a gain of 1), and $\mathtt{g}_{U}(d@k)=0$ otherwise. In the graded version, understandability assessments are transformed into estimations of the probability function $P(U|d@k)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

